{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "egyptian-simpson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T03:18:30.970611Z",
     "start_time": "2021-02-11T03:18:30.957645Z"
    }
   },
   "source": [
    "**CS547 HW2**  \n",
    "Yue Cui  \n",
    "Gaoyu Liu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-arbitration",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-timeline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "matched-referral",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-austin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "residential-least",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "revised-mainland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T06:43:28.124874Z",
     "start_time": "2021-02-11T06:43:26.321124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.7.1\n",
      "\n",
      "Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas 1.2.1\n",
      "Scikit-Learn 0.23.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-property",
   "metadata": {},
   "source": [
    "Generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "waiting-horse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T15:23:36.718724Z",
     "start_time": "2021-02-11T15:23:36.709747Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate 200 Gausian points\n",
    "torch.manual_seed(1)\n",
    "N = 200\n",
    "\n",
    "data_input = torch.Tensor(N, 1).normal_(mean = 0., std = 1.)\n",
    "#print(data_input)\n",
    "\n",
    "labels_input = (data_input > 0).float()\n",
    "#print(labels_input)\n",
    "\n",
    "# check for GPU\n",
    "if torch.cuda.is_available():\n",
    "    data_input = data_input.cuda()\n",
    "    labels_input = labels_input.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-softball",
   "metadata": {},
   "source": [
    "## (1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-worth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:50:55.313103Z",
     "start_time": "2021-02-11T05:50:55.296803Z"
    }
   },
   "source": [
    "Define the class **LogisticRegression** using Pytorch. The Sigmoid function \n",
    "\n",
    "$$\n",
    "S_{m, b}\\ (X) = \\frac{e^{mX+b}}{1 + e^{mX+b}}\n",
    "$$\n",
    "\n",
    "is used and a entropy function for binary classification problem is adopted, namely, **torch.nn.BCEWithLogitsLoss**.  \n",
    "\n",
    "For each training sample, the input $X$ is a scalar with dimension 1, the output $z$ is also a scalar with dimension of 1.  \n",
    "\n",
    "The learning rate is set to be 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "vulnerable-bobby",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:22:30.115079Z",
     "start_time": "2021-02-11T17:22:30.098125Z"
    }
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "        self.linear = torch.nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "    \n",
    "# flip n*2 points as needed (for (2) and (3))\n",
    "def flip_n(data, labels, n):\n",
    "    if n == 0:\n",
    "        return labels.clone()\n",
    "    # get the assending sorted indices\n",
    "    sort_idx = data.argsort(dim=0)\n",
    "    # get the total number of negative numbers\n",
    "    num_neg = sum(data < 0)\n",
    "    # get the indices to flip the labels\n",
    "    flip_idx_neg = sort_idx[num_neg - n: num_neg]\n",
    "    flip_idx_pos = sort_idx[num_neg: num_neg + n]\n",
    "    # carry out the label flipping\n",
    "    labels_res = labels.clone()\n",
    "    labels_res[flip_idx_neg] = 1.\n",
    "    labels_res[flip_idx_pos] = 0.\n",
    "    # return the result\n",
    "    return labels_res\n",
    "\n",
    "\n",
    "\n",
    "def Carryout_logi_regression(data_input,\n",
    "                             labels_input,\n",
    "                             n=0,\n",
    "                             lr=.1, max_iter=10000,\n",
    "                             ):\n",
    "    # process the labels\n",
    "    labels_n = flip_n(data_input, labels_input, n)\n",
    "\n",
    "    # instantiate the model object\n",
    "    input_dim = 1  # data_raw.size()[0]\n",
    "    num_classes = 1\n",
    "\n",
    "    model = LogisticRegression(input_dim, num_classes)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    #Loss = torch.nn.CrossEntropyLoss()\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n",
    "    Loss = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "    learningRate = lr\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "\n",
    "    for itr in range(max_iter):\n",
    "        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward,\n",
    "        # dont want to cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        outputs = model(data_input)\n",
    "        # print(outputs.size())\n",
    "        # print(labels_input.size())\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        lossvalue = Loss(outputs, labels_n)\n",
    "\n",
    "        # get gradients w.r.t to parameters\n",
    "        lossvalue.backward()\n",
    "        # print(model.linear.weight.grad.item(),model.linear.bias.grad.item())\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        if itr % 1000 == 0:\n",
    "            print(\"iteration {}: loss={:.5f}, width={:.5f} \".format(itr, lossvalue.item(),\n",
    "                                                                    1/model.linear.weight.item()))\n",
    "    #\n",
    "    print(f'The width of the transition layer for the model with {n} points\\n',\n",
    "        f'flipped on each side of 0 is {1/model.linear.weight.item():.5f}')\n",
    "    print(f'===============================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-impression",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T06:13:45.693317Z",
     "start_time": "2021-02-11T06:13:45.674370Z"
    }
   },
   "source": [
    "Now carry out the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "acting-equipment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:22:39.029236Z",
     "start_time": "2021-02-11T17:22:31.743439Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss=1.11191, width=-1.31348 \n",
      "iteration 1000: loss=0.11352, width=0.19088 \n",
      "iteration 2000: loss=0.08885, width=0.14720 \n",
      "iteration 3000: loss=0.07718, width=0.12707 \n",
      "iteration 4000: loss=0.06985, width=0.11462 \n",
      "iteration 5000: loss=0.06462, width=0.10586 \n",
      "iteration 6000: loss=0.06062, width=0.09922 \n",
      "iteration 7000: loss=0.05741, width=0.09394 \n",
      "iteration 8000: loss=0.05476, width=0.08961 \n",
      "iteration 9000: loss=0.05251, width=0.08596 \n",
      "The width of the transition layer for the model with 0 points\n",
      " flipped on each side of 0 is 0.08283\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Carryout_logi_regression(data_input,\n",
    "                         labels_input,\n",
    "                         n=0,\n",
    "                         lr=.1, max_iter=10000,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-symphony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T15:22:39.518204Z",
     "start_time": "2021-02-11T15:22:39.480304Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "productive-audit",
   "metadata": {},
   "source": [
    "## (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "requested-bronze",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:23:17.424367Z",
     "start_time": "2021-02-11T17:23:11.821535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss=0.54241, width=2.22001 \n",
      "iteration 1000: loss=0.12399, width=0.19276 \n",
      "iteration 2000: loss=0.10315, width=0.15117 \n",
      "iteration 3000: loss=0.09383, width=0.13199 \n",
      "iteration 4000: loss=0.08827, width=0.12019 \n",
      "iteration 5000: loss=0.08450, width=0.11194 \n",
      "iteration 6000: loss=0.08175, width=0.10573 \n",
      "iteration 7000: loss=0.07963, width=0.10084 \n",
      "iteration 8000: loss=0.07796, width=0.09684 \n",
      "iteration 9000: loss=0.07659, width=0.09350 \n",
      "The width of the transition layer for the model with 5 points\n",
      " flipped on each side of 0 is 0.09065\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Carryout_logi_regression(data_input,\n",
    "                         labels_input,\n",
    "                         n=5,\n",
    "                         lr=.1, max_iter=10000,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-sally",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:03:42.511999Z",
     "start_time": "2021-02-11T17:03:36.813685Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "welsh-valley",
   "metadata": {},
   "source": [
    "## (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "exciting-incentive",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:24:39.924461Z",
     "start_time": "2021-02-11T17:24:09.716732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss=0.92879, width=-2.19939 \n",
      "iteration 1000: loss=0.20018, width=0.22589 \n",
      "iteration 2000: loss=0.19349, width=0.19159 \n",
      "iteration 3000: loss=0.19206, width=0.17886 \n",
      "iteration 4000: loss=0.19164, width=0.17261 \n",
      "iteration 5000: loss=0.19150, width=0.16918 \n",
      "iteration 6000: loss=0.19144, width=0.16720 \n",
      "iteration 7000: loss=0.19143, width=0.16601 \n",
      "iteration 8000: loss=0.19142, width=0.16529 \n",
      "iteration 9000: loss=0.19142, width=0.16485 \n",
      "The width of the transition layer for the model with 15 points\n",
      " flipped on each side of 0 is 0.16457\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=1.18146, width=-1.13302 \n",
      "iteration 1000: loss=0.25142, width=0.25614 \n",
      "iteration 2000: loss=0.24921, width=0.23024 \n",
      "iteration 3000: loss=0.24903, width=0.22353 \n",
      "iteration 4000: loss=0.24901, width=0.22138 \n",
      "iteration 5000: loss=0.24900, width=0.22065 \n",
      "iteration 6000: loss=0.24900, width=0.22039 \n",
      "iteration 7000: loss=0.24900, width=0.22031 \n",
      "iteration 8000: loss=0.24900, width=0.22027 \n",
      "iteration 9000: loss=0.24900, width=0.22027 \n",
      "The width of the transition layer for the model with 20 points\n",
      " flipped on each side of 0 is 0.22027\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=1.10833, width=-1.62926 \n",
      "iteration 1000: loss=0.30499, width=0.29787 \n",
      "iteration 2000: loss=0.30456, width=0.28270 \n",
      "iteration 3000: loss=0.30455, width=0.28071 \n",
      "iteration 4000: loss=0.30455, width=0.28042 \n",
      "iteration 5000: loss=0.30455, width=0.28038 \n",
      "iteration 6000: loss=0.30455, width=0.28038 \n",
      "iteration 7000: loss=0.30455, width=0.28038 \n",
      "iteration 8000: loss=0.30455, width=0.28038 \n",
      "iteration 9000: loss=0.30455, width=0.28038 \n",
      "The width of the transition layer for the model with 25 points\n",
      " flipped on each side of 0 is 0.28038\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=0.47807, width=1.11494 \n",
      "iteration 1000: loss=0.36890, width=0.36714 \n",
      "iteration 2000: loss=0.36888, width=0.36274 \n",
      "iteration 3000: loss=0.36888, width=0.36259 \n",
      "iteration 4000: loss=0.36888, width=0.36259 \n",
      "iteration 5000: loss=0.36888, width=0.36259 \n",
      "iteration 6000: loss=0.36888, width=0.36259 \n",
      "iteration 7000: loss=0.36888, width=0.36259 \n",
      "iteration 8000: loss=0.36888, width=0.36259 \n",
      "iteration 9000: loss=0.36888, width=0.36259 \n",
      "The width of the transition layer for the model with 30 points\n",
      " flipped on each side of 0 is 0.36259\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=0.72108, width=13.02823 \n",
      "iteration 1000: loss=0.42857, width=0.45941 \n",
      "iteration 2000: loss=0.42857, width=0.45840 \n",
      "iteration 3000: loss=0.42857, width=0.45840 \n",
      "iteration 4000: loss=0.42857, width=0.45840 \n",
      "iteration 5000: loss=0.42857, width=0.45840 \n",
      "iteration 6000: loss=0.42857, width=0.45840 \n",
      "iteration 7000: loss=0.42857, width=0.45840 \n",
      "iteration 8000: loss=0.42857, width=0.45840 \n",
      "iteration 9000: loss=0.42857, width=0.45840 \n",
      "The width of the transition layer for the model with 35 points\n",
      " flipped on each side of 0 is 0.45840\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in [15, 20, 25, 30, 35]:\n",
    "    Carryout_logi_regression(data_input,\n",
    "                             labels_input,\n",
    "                             n=item,\n",
    "                             lr=.1, max_iter=10000,\n",
    "                             )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-bicycle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "189.531px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 265.30080799999996,
   "position": {
    "height": "40px",
    "left": "849.704px",
    "right": "20px",
    "top": "120px",
    "width": "527.993px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
