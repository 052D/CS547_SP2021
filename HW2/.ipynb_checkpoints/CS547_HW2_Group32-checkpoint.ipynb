{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "egyptian-simpson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T03:18:30.970611Z",
     "start_time": "2021-02-11T03:18:30.957645Z"
    }
   },
   "source": [
    "**CS547 HW2**  \n",
    "Yue Cui (yuecui2)  \n",
    "Gaoyu Liu (gliu18)\n",
    "\n",
    "Colab link:  \n",
    "https://colab.research.google.com/github/052D/CS547_SP2021/blob/main/HW2/CS547_HW2_Group32.ipynb?authuser=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-arbitration",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-prisoner",
   "metadata": {},
   "source": [
    "$$\n",
    "H(p',p) = p'\\ln \\frac{p'}{p}+(1-p')\\ln \\frac{1-p'}{1-p}\n",
    "$$\n",
    "\n",
    "Take the derivative of $H(p', p)$ w.r.t $p'$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial H}{\\partial p'} = \n",
    "\\ln(\\frac{p'}{p}) + p' \\cdot \\frac{p'}{p} \\cdot \\frac{1}{p}\n",
    "- \\ln \\frac{1 - p'}{1 - p} + (1 - p') \\cdot \\frac{1 - p}{1 - p'} \\cdot \\frac{-1}{1 - p} \\\\\n",
    "\\frac{\\partial H}{\\partial p'} = \\ln \\frac{p'}{p} - \\ln \\frac{1 - p'}{1 - p}\n",
    "$$\n",
    "\n",
    "Now, compute the second order derivitaive of $H(p', p)$ w.r.t $p'$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 H}{\\partial p'^2} = \n",
    "\\frac{p}{p'} \\cdot \\frac{1}{p} -\n",
    "\\frac{1 - p}{1 - p'} \\cdot \\frac{-1}{1 - p} \\\\\n",
    "= \\frac{1}{p'} + \\frac{1}{1 - p'} > 0\n",
    "$$\n",
    "\n",
    "Since the second order derivitaive of $H(p', p)$ w.r.t $p'$ is strictly positive, $p' \\mapsto H(p',p)$ is **convex** for $p \\in (0, 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-referral",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-player",
   "metadata": {},
   "source": [
    "Take the first derivative of $f(\\theta)=\\theta p'-\\ln\\{pe^{\\theta}+(1-p)\\}$ with respect to $\\theta$, we have:\n",
    "\n",
    "$$\n",
    "\\frac{df(\\theta)}{d\\theta}=p'-\\frac{pe^{\\theta}}{pe^{\\theta}+(1-p)}\n",
    "$$\n",
    "\n",
    "To find $\\theta$ that maximize $f(\\theta)$, we set $\\frac{df(\\theta)}{d\\theta}=0$, hence:\n",
    "\n",
    "$$\n",
    "p'-\\frac{pe^{\\theta}}{pe^{\\theta}+(1-p)}=0 \\\\\n",
    "p'pe^{\\theta}+p'(1-p)=pe^{\\theta} \\\\\n",
    "(p'p-p)e^{\\theta}=-p'(1-p) \\\\\n",
    "e^{\\theta}=\\frac{p'-pp'}{p-p'p} \\\\\n",
    "\\theta=\\ln\\frac{p'-pp'}{p-pp'}\n",
    "$$\n",
    "\n",
    "Now substitute $\\theta=\\ln\\frac{p'-pp'}{p-p'p}$ back to $f(\\theta)$:\n",
    "\n",
    "$$\n",
    "\\max_{\\theta \\in R} \\{ \\theta p'-\\ln \\{ pe^\\theta+(1-p)\\} \\}=p'\\ln\\frac{p'-pp'}{p-pp'}-\\ln\\{ pe^{\\ln\\frac{p'-pp'}{p-pp'}}+(1-p) \\} \\\\\n",
    "= p'\\ln\\frac{p'(1-p)}{p(1-p')}-\\ln\\{ p\\frac{p'-pp'}{p-pp'}+(1-p) \\} \\\\\n",
    "= p'(\\ln\\frac{p'}{p}+\\ln\\frac{1-p}{1-p'})-\\ln\\{ \\frac{p(p'-pp')+(p-pp')(1-p)}{p-pp'} \\} \\\\\n",
    "=p'\\ln\\frac{p'}{p}+p'\\ln\\frac{1-p}{1-p'}-\\ln\\frac{1-p}{1-p'} \\\\\n",
    "=p'\\ln\\frac{p'}{p}+(1-p')\\ln\\frac{1-p'}{1-p}\n",
    "$$\n",
    "\n",
    "The result gives the **entropy function**. Therefore, it is verified that the Legendre-Fenchel transform of the logarithm of the moment generating function of a Bernoulli random variable $\\ln \\{ pe^\\theta+(1-p)\\}$ indeed is the entropy function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-least",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "revised-mainland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T04:39:30.092075Z",
     "start_time": "2021-02-14T04:39:29.145435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.7.1\n",
      "\n",
      "Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas 1.2.1\n",
      "Scikit-Learn 0.23.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-property",
   "metadata": {},
   "source": [
    "Generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "waiting-horse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T15:23:36.718724Z",
     "start_time": "2021-02-11T15:23:36.709747Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate 200 Gausian points\n",
    "torch.manual_seed(1)\n",
    "N = 200\n",
    "\n",
    "data_input = torch.Tensor(N, 1).normal_(mean = 0., std = 1.)\n",
    "#print(data_input)\n",
    "\n",
    "labels_input = (data_input > 0).float()\n",
    "#print(labels_input)\n",
    "\n",
    "# check for GPU\n",
    "if torch.cuda.is_available():\n",
    "    data_input = data_input.cuda()\n",
    "    labels_input = labels_input.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-softball",
   "metadata": {},
   "source": [
    "## (1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-worth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:50:55.313103Z",
     "start_time": "2021-02-11T05:50:55.296803Z"
    }
   },
   "source": [
    "Define the class **LogisticRegression** using Pytorch. The Sigmoid function \n",
    "\n",
    "$$\n",
    "S_{m, b}\\ (X) = \\frac{e^{mX+b}}{1 + e^{mX+b}}\n",
    "$$\n",
    "\n",
    "is used and a entropy function for binary classification problem is adopted, namely, **torch.nn.BCEWithLogitsLoss**.  \n",
    "\n",
    "For each training sample, the input $X$ is a scalar with dimension 1, the output $z$ is also a scalar with dimension of 1.  \n",
    "\n",
    "The learning rate is set to be 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "vulnerable-bobby",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T04:21:29.074510Z",
     "start_time": "2021-02-14T04:21:29.049579Z"
    }
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "        self.linear = torch.nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "    \n",
    "# flip n*2 points as needed (for (2) and (3))\n",
    "def flip_n(data, labels, n):\n",
    "    if n == 0:\n",
    "        return labels.clone()\n",
    "    # get the assending sorted indices\n",
    "    sort_idx = data.argsort(dim=0)\n",
    "    # get the total number of negative numbers\n",
    "    num_neg = sum(data < 0)\n",
    "    # get the indices to flip the labels\n",
    "    flip_idx_neg = sort_idx[num_neg - n: num_neg]\n",
    "    flip_idx_pos = sort_idx[num_neg: num_neg + n]\n",
    "    # carry out the label flipping\n",
    "    labels_res = labels.clone()\n",
    "    labels_res[flip_idx_neg] = 1.\n",
    "    labels_res[flip_idx_pos] = 0.\n",
    "    # return the result\n",
    "    return labels_res\n",
    "\n",
    "\n",
    "\n",
    "def Carryout_logi_regression(data_input,\n",
    "                             labels_input,\n",
    "                             n=0,\n",
    "                             lr=.1, max_iter=10000,\n",
    "                             ):\n",
    "    # process the labels\n",
    "    labels_n = flip_n(data_input, labels_input, n)\n",
    "\n",
    "    # instantiate the model object\n",
    "    input_dim = 1  # data_raw.size()[0]\n",
    "    num_classes = 1\n",
    "\n",
    "    model = LogisticRegression(input_dim, num_classes)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    #Loss = torch.nn.CrossEntropyLoss()\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n",
    "    Loss = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "    learningRate = lr\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "\n",
    "    for itr in range(max_iter):\n",
    "        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward,\n",
    "        # dont want to cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        outputs = model(data_input)\n",
    "        # print(outputs.size())\n",
    "        # print(labels_input.size())\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        lossvalue = Loss(outputs, labels_n)\n",
    "\n",
    "        # get gradients w.r.t to parameters\n",
    "        lossvalue.backward()\n",
    "        # print(model.linear.weight.grad.item(),model.linear.bias.grad.item())\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        if itr % 10000 == 0:\n",
    "            print(\"iteration {}: loss={:.5f}, width={:.5f} \".format(itr, lossvalue.item(),\n",
    "                                                                    1/model.linear.weight.item()))\n",
    "    #\n",
    "    print(f'The width of the transition layer for the model with {n} points\\n',\n",
    "        f'flipped on each side of 0 is {1/model.linear.weight.item():.5f}')\n",
    "    print(f'===============================================\\n')\n",
    "    \n",
    "    return 1/model.linear.weight.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-impression",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T06:13:45.693317Z",
     "start_time": "2021-02-11T06:13:45.674370Z"
    }
   },
   "source": [
    "Now carry out the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "acting-equipment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T04:22:42.491879Z",
     "start_time": "2021-02-14T04:21:46.226968Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss=0.45614, width=1.14401 \n",
      "iteration 10000: loss=0.05049, width=0.08269 \n",
      "iteration 20000: loss=0.03935, width=0.06494 \n",
      "iteration 30000: loss=0.03399, width=0.05647 \n",
      "iteration 40000: loss=0.03065, width=0.05120 \n",
      "iteration 50000: loss=0.02831, width=0.04748 \n",
      "iteration 60000: loss=0.02654, width=0.04466 \n",
      "iteration 70000: loss=0.02514, width=0.04242 \n",
      "iteration 80000: loss=0.02399, width=0.04058 \n",
      "iteration 90000: loss=0.02303, width=0.03903 \n",
      "The width of the transition layer for the model with 0 points\n",
      " flipped on each side of 0 is 0.03770\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "width_0 = Carryout_logi_regression(data_input,\n",
    "                                   labels_input,\n",
    "                                   n=0,\n",
    "                                   lr=0.1, max_iter=100000,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "composed-symphony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T04:27:54.361621Z",
     "start_time": "2021-02-14T04:27:54.341660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03769566])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width_result = np.array([])\n",
    "width_result = np.append(width_result, width_0)\n",
    "display(width_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-audit",
   "metadata": {},
   "source": [
    "## (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "requested-bronze",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T04:29:20.471918Z",
     "start_time": "2021-02-14T04:28:21.694087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss=0.68865, width=20.24849 \n",
      "iteration 10000: loss=0.07547, width=0.09068 \n",
      "iteration 20000: loss=0.06993, width=0.07495 \n",
      "iteration 30000: loss=0.06804, width=0.06800 \n",
      "iteration 40000: loss=0.06718, width=0.06399 \n",
      "iteration 50000: loss=0.06673, width=0.06138 \n",
      "iteration 60000: loss=0.06649, width=0.05957 \n",
      "iteration 70000: loss=0.06634, width=0.05826 \n",
      "iteration 80000: loss=0.06626, width=0.05728 \n",
      "iteration 90000: loss=0.06620, width=0.05653 \n",
      "The width of the transition layer for the model with 5 points\n",
      " flipped on each side of 0 is 0.05594\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "width_5 = Carryout_logi_regression(data_input,\n",
    "                                   labels_input,\n",
    "                                   n=5,\n",
    "                                   lr=.1, max_iter=100000,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "disturbed-sally",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T04:29:25.235709Z",
     "start_time": "2021-02-14T04:29:25.228728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03769566, 0.05594289])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width_result = np.append(width_result, width_5)\n",
    "display(width_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-valley",
   "metadata": {},
   "source": [
    "## (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "exciting-incentive",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T04:34:46.429540Z",
     "start_time": "2021-02-14T04:29:59.975995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss=0.96724, width=-1.78957 \n",
      "iteration 10000: loss=0.31989, width=0.59803 \n",
      "iteration 20000: loss=0.26009, width=0.41097 \n",
      "iteration 30000: loss=0.23664, width=0.34307 \n",
      "iteration 40000: loss=0.22399, width=0.30587 \n",
      "iteration 50000: loss=0.21612, width=0.28173 \n",
      "iteration 60000: loss=0.21078, width=0.26453 \n",
      "iteration 70000: loss=0.20696, width=0.25154 \n",
      "iteration 80000: loss=0.20412, width=0.24132 \n",
      "iteration 90000: loss=0.20194, width=0.23302 \n",
      "The width of the transition layer for the model with 15 points\n",
      " flipped on each side of 0 is 0.22614\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=0.60948, width=3.96420 \n",
      "iteration 10000: loss=0.32823, width=0.55989 \n",
      "iteration 20000: loss=0.28800, width=0.41470 \n",
      "iteration 30000: loss=0.27222, width=0.35635 \n",
      "iteration 40000: loss=0.26411, width=0.32363 \n",
      "iteration 50000: loss=0.25936, width=0.30235 \n",
      "iteration 60000: loss=0.25635, width=0.28732 \n",
      "iteration 70000: loss=0.25435, width=0.27610 \n",
      "iteration 80000: loss=0.25296, width=0.26743 \n",
      "iteration 90000: loss=0.25198, width=0.26052 \n",
      "The width of the transition layer for the model with 20 points\n",
      " flipped on each side of 0 is 0.25491\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=0.94369, width=-1.96092 \n",
      "iteration 10000: loss=0.37282, width=0.64915 \n",
      "iteration 20000: loss=0.33087, width=0.46021 \n",
      "iteration 30000: loss=0.31761, width=0.39468 \n",
      "iteration 40000: loss=0.31177, width=0.36050 \n",
      "iteration 50000: loss=0.30879, width=0.33947 \n",
      "iteration 60000: loss=0.30714, width=0.32532 \n",
      "iteration 70000: loss=0.30618, width=0.31527 \n",
      "iteration 80000: loss=0.30559, width=0.30786 \n",
      "iteration 90000: loss=0.30523, width=0.30225 \n",
      "The width of the transition layer for the model with 25 points\n",
      " flipped on each side of 0 is 0.29793\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=1.21433, width=-1.20772 \n",
      "iteration 10000: loss=0.41800, width=0.72365 \n",
      "iteration 20000: loss=0.38264, width=0.51319 \n",
      "iteration 30000: loss=0.37413, width=0.44730 \n",
      "iteration 40000: loss=0.37114, width=0.41544 \n",
      "iteration 50000: loss=0.36991, width=0.39730 \n",
      "iteration 60000: loss=0.36937, width=0.38606 \n",
      "iteration 70000: loss=0.36912, width=0.37875 \n",
      "iteration 80000: loss=0.36900, width=0.37385 \n",
      "iteration 90000: loss=0.36894, width=0.37049 \n",
      "The width of the transition layer for the model with 30 points\n",
      " flipped on each side of 0 is 0.36818\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=0.74995, width=-5.87976 \n",
      "iteration 10000: loss=0.45199, width=0.73994 \n",
      "iteration 20000: loss=0.43374, width=0.56652 \n",
      "iteration 30000: loss=0.43003, width=0.51176 \n",
      "iteration 40000: loss=0.42903, width=0.48717 \n",
      "iteration 50000: loss=0.42872, width=0.47456 \n",
      "iteration 60000: loss=0.42862, width=0.46767 \n",
      "iteration 70000: loss=0.42859, width=0.46378 \n",
      "iteration 80000: loss=0.42858, width=0.46155 \n",
      "iteration 90000: loss=0.42857, width=0.46027 \n",
      "The width of the transition layer for the model with 35 points\n",
      " flipped on each side of 0 is 0.45954\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in [15, 20, 25, 30, 35]:\n",
    "    width_ = Carryout_logi_regression(data_input,\n",
    "                                      labels_input,\n",
    "                                      n=item,\n",
    "                                      lr=.001, max_iter=100000,\n",
    "                                      )\n",
    "    #\n",
    "    width_result = np.append(width_result, width_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-piano",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T04:37:12.588397Z",
     "start_time": "2021-02-14T04:37:12.570444Z"
    }
   },
   "source": [
    "The transition layer width vs number of points with the 'wrong' label on each side of the origin is ploted below. As the number of 'wrong' label points increases, the trainsition layer width increases, indicating that the training data with the wrong labels make the trained logistic regression model have extended transition layer in which the prediction accuracy may decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "planned-bicycle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T04:41:40.752451Z",
     "start_time": "2021-02-14T04:41:40.631002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.delete(np.arange(0, 40, 5), 2), width_result,\n",
    "         label=\"Width\",\n",
    "         color=\"red\")\n",
    "\n",
    "title = []\n",
    "title.append(\"Transition Layer Width\")\n",
    "plt.title(\"\\n\".join(title))\n",
    "plt.xlabel(\"Number of flipped points on each side of origin\")\n",
    "plt.ylabel(\"1/m\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "189.531px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 265.30080799999996,
   "position": {
    "height": "40px",
    "left": "849.704px",
    "right": "20px",
    "top": "120px",
    "width": "527.993px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
