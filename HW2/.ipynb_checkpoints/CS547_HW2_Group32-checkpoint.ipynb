{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "egyptian-simpson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T03:18:30.970611Z",
     "start_time": "2021-02-11T03:18:30.957645Z"
    }
   },
   "source": [
    "**CS547 HW2**  \n",
    "Yue Cui  \n",
    "Gaoyu Liu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-arbitration",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-table",
   "metadata": {},
   "source": [
    "$$\n",
    "H(p',p) = p'\\ln \\frac{p'}{p}+(1-p')\\ln \\frac{1-p'}{1-p}\n",
    "$$\n",
    "\n",
    "Take the derivative of $H(p', p)$ w.r.t $p'$:\n",
    "\n",
    "$$\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-referral",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-austin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "residential-least",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "revised-mainland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T06:43:28.124874Z",
     "start_time": "2021-02-11T06:43:26.321124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.7.1\n",
      "\n",
      "Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas 1.2.1\n",
      "Scikit-Learn 0.23.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-property",
   "metadata": {},
   "source": [
    "Generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "waiting-horse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T15:23:36.718724Z",
     "start_time": "2021-02-11T15:23:36.709747Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate 200 Gausian points\n",
    "torch.manual_seed(1)\n",
    "N = 200\n",
    "\n",
    "data_input = torch.Tensor(N, 1).normal_(mean = 0., std = 1.)\n",
    "#print(data_input)\n",
    "\n",
    "labels_input = (data_input > 0).float()\n",
    "#print(labels_input)\n",
    "\n",
    "# check for GPU\n",
    "if torch.cuda.is_available():\n",
    "    data_input = data_input.cuda()\n",
    "    labels_input = labels_input.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-softball",
   "metadata": {},
   "source": [
    "## (1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-worth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T05:50:55.313103Z",
     "start_time": "2021-02-11T05:50:55.296803Z"
    }
   },
   "source": [
    "Define the class **LogisticRegression** using Pytorch. The Sigmoid function \n",
    "\n",
    "$$\n",
    "S_{m, b}\\ (X) = \\frac{e^{mX+b}}{1 + e^{mX+b}}\n",
    "$$\n",
    "\n",
    "is used and a entropy function for binary classification problem is adopted, namely, **torch.nn.BCEWithLogitsLoss**.  \n",
    "\n",
    "For each training sample, the input $X$ is a scalar with dimension 1, the output $z$ is also a scalar with dimension of 1.  \n",
    "\n",
    "The learning rate is set to be 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "vulnerable-bobby",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T06:11:16.650956Z",
     "start_time": "2021-02-12T06:11:16.628542Z"
    }
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "        self.linear = torch.nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "    \n",
    "# flip n*2 points as needed (for (2) and (3))\n",
    "def flip_n(data, labels, n):\n",
    "    if n == 0:\n",
    "        return labels.clone()\n",
    "    # get the assending sorted indices\n",
    "    sort_idx = data.argsort(dim=0)\n",
    "    # get the total number of negative numbers\n",
    "    num_neg = sum(data < 0)\n",
    "    # get the indices to flip the labels\n",
    "    flip_idx_neg = sort_idx[num_neg - n: num_neg]\n",
    "    flip_idx_pos = sort_idx[num_neg: num_neg + n]\n",
    "    # carry out the label flipping\n",
    "    labels_res = labels.clone()\n",
    "    labels_res[flip_idx_neg] = 1.\n",
    "    labels_res[flip_idx_pos] = 0.\n",
    "    # return the result\n",
    "    return labels_res\n",
    "\n",
    "\n",
    "\n",
    "def Carryout_logi_regression(data_input,\n",
    "                             labels_input,\n",
    "                             n=0,\n",
    "                             lr=.1, max_iter=10000,\n",
    "                             ):\n",
    "    # process the labels\n",
    "    labels_n = flip_n(data_input, labels_input, n)\n",
    "\n",
    "    # instantiate the model object\n",
    "    input_dim = 1  # data_raw.size()[0]\n",
    "    num_classes = 1\n",
    "\n",
    "    model = LogisticRegression(input_dim, num_classes)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    #Loss = torch.nn.CrossEntropyLoss()\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n",
    "    Loss = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "    learningRate = lr\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "\n",
    "    for itr in range(max_iter):\n",
    "        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward,\n",
    "        # dont want to cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get output from the model, given the inputs\n",
    "        outputs = model(data_input)\n",
    "        # print(outputs.size())\n",
    "        # print(labels_input.size())\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        lossvalue = Loss(outputs, labels_n)\n",
    "\n",
    "        # get gradients w.r.t to parameters\n",
    "        lossvalue.backward()\n",
    "        # print(model.linear.weight.grad.item(),model.linear.bias.grad.item())\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        if itr % 10000 == 0:\n",
    "            print(\"iteration {}: loss={:.5f}, width={:.5f} \".format(itr, lossvalue.item(),\n",
    "                                                                    1/model.linear.weight.item()))\n",
    "    #\n",
    "    print(f'The width of the transition layer for the model with {n} points\\n',\n",
    "        f'flipped on each side of 0 is {1/model.linear.weight.item():.5f}')\n",
    "    print(f'===============================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-impression",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T06:13:45.693317Z",
     "start_time": "2021-02-11T06:13:45.674370Z"
    }
   },
   "source": [
    "Now carry out the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "acting-equipment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T06:13:34.038316Z",
     "start_time": "2021-02-12T06:12:34.709957Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss=0.54682, width=1.46370 \n",
      "iteration 10000: loss=0.05050, width=0.08271 \n",
      "iteration 20000: loss=0.03936, width=0.06494 \n",
      "iteration 30000: loss=0.03400, width=0.05648 \n",
      "iteration 40000: loss=0.03066, width=0.05120 \n",
      "iteration 50000: loss=0.02831, width=0.04748 \n",
      "iteration 60000: loss=0.02654, width=0.04467 \n",
      "iteration 70000: loss=0.02514, width=0.04242 \n",
      "iteration 80000: loss=0.02400, width=0.04058 \n",
      "iteration 90000: loss=0.02303, width=0.03903 \n",
      "The width of the transition layer for the model with 0 points\n",
      " flipped on each side of 0 is 0.03770\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Carryout_logi_regression(data_input,\n",
    "                         labels_input,\n",
    "                         n=0,\n",
    "                         lr=0.1, max_iter=100000,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-symphony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T15:22:39.518204Z",
     "start_time": "2021-02-11T15:22:39.480304Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "productive-audit",
   "metadata": {},
   "source": [
    "## (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "requested-bronze",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T06:17:15.125372Z",
     "start_time": "2021-02-12T06:16:13.807803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss=0.77725, width=-6.59151 \n",
      "iteration 10000: loss=0.07548, width=0.09069 \n",
      "iteration 20000: loss=0.06993, width=0.07495 \n",
      "iteration 30000: loss=0.06804, width=0.06800 \n",
      "iteration 40000: loss=0.06718, width=0.06399 \n",
      "iteration 50000: loss=0.06673, width=0.06138 \n",
      "iteration 60000: loss=0.06649, width=0.05957 \n",
      "iteration 70000: loss=0.06634, width=0.05826 \n",
      "iteration 80000: loss=0.06626, width=0.05728 \n",
      "iteration 90000: loss=0.06620, width=0.05653 \n",
      "The width of the transition layer for the model with 5 points\n",
      " flipped on each side of 0 is 0.05594\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Carryout_logi_regression(data_input,\n",
    "                         labels_input,\n",
    "                         n=5,\n",
    "                         lr=.1, max_iter=100000,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-sally",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:03:42.511999Z",
     "start_time": "2021-02-11T17:03:36.813685Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "welsh-valley",
   "metadata": {},
   "source": [
    "## (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "exciting-incentive",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T06:22:06.709785Z",
     "start_time": "2021-02-12T06:17:15.467686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss=0.77496, width=-5.27807 \n",
      "iteration 10000: loss=0.31211, width=0.57211 \n",
      "iteration 20000: loss=0.25764, width=0.40385 \n",
      "iteration 30000: loss=0.23543, width=0.33955 \n",
      "iteration 40000: loss=0.22327, width=0.30370 \n",
      "iteration 50000: loss=0.21564, width=0.28024 \n",
      "iteration 60000: loss=0.21045, width=0.26343 \n",
      "iteration 70000: loss=0.20672, width=0.25069 \n",
      "iteration 80000: loss=0.20393, width=0.24063 \n",
      "iteration 90000: loss=0.20179, width=0.23246 \n",
      "The width of the transition layer for the model with 15 points\n",
      " flipped on each side of 0 is 0.22566\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=0.55553, width=2.39460 \n",
      "iteration 10000: loss=0.32448, width=0.54613 \n",
      "iteration 20000: loss=0.28679, width=0.41034 \n",
      "iteration 30000: loss=0.27165, width=0.35412 \n",
      "iteration 40000: loss=0.26379, width=0.32225 \n",
      "iteration 50000: loss=0.25916, width=0.30141 \n",
      "iteration 60000: loss=0.25622, width=0.28663 \n",
      "iteration 70000: loss=0.25426, width=0.27558 \n",
      "iteration 80000: loss=0.25290, width=0.26701 \n",
      "iteration 90000: loss=0.25193, width=0.26019 \n",
      "The width of the transition layer for the model with 20 points\n",
      " flipped on each side of 0 is 0.25464\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=0.95860, width=-1.78168 \n",
      "iteration 10000: loss=0.37346, width=0.65305 \n",
      "iteration 20000: loss=0.33106, width=0.46116 \n",
      "iteration 30000: loss=0.31769, width=0.39511 \n",
      "iteration 40000: loss=0.31181, width=0.36075 \n",
      "iteration 50000: loss=0.30882, width=0.33963 \n",
      "iteration 60000: loss=0.30716, width=0.32544 \n",
      "iteration 70000: loss=0.30618, width=0.31535 \n",
      "iteration 80000: loss=0.30560, width=0.30792 \n",
      "iteration 90000: loss=0.30523, width=0.30230 \n",
      "The width of the transition layer for the model with 25 points\n",
      " flipped on each side of 0 is 0.29796\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=1.00825, width=-1.38449 \n",
      "iteration 10000: loss=0.41572, width=0.71950 \n",
      "iteration 20000: loss=0.38249, width=0.51251 \n",
      "iteration 30000: loss=0.37410, width=0.44703 \n",
      "iteration 40000: loss=0.37113, width=0.41530 \n",
      "iteration 50000: loss=0.36991, width=0.39722 \n",
      "iteration 60000: loss=0.36937, width=0.38601 \n",
      "iteration 70000: loss=0.36912, width=0.37872 \n",
      "iteration 80000: loss=0.36900, width=0.37383 \n",
      "iteration 90000: loss=0.36894, width=0.37048 \n",
      "The width of the transition layer for the model with 30 points\n",
      " flipped on each side of 0 is 0.36817\n",
      "===============================================\n",
      "\n",
      "iteration 0: loss=0.58925, width=1.95610 \n",
      "iteration 10000: loss=0.44417, width=0.66725 \n",
      "iteration 20000: loss=0.43223, width=0.54692 \n",
      "iteration 30000: loss=0.42964, width=0.50346 \n",
      "iteration 40000: loss=0.42891, width=0.48302 \n",
      "iteration 50000: loss=0.42868, width=0.47232 \n",
      "iteration 60000: loss=0.42861, width=0.46641 \n",
      "iteration 70000: loss=0.42858, width=0.46307 \n",
      "iteration 80000: loss=0.42858, width=0.46115 \n",
      "iteration 90000: loss=0.42857, width=0.46001 \n",
      "The width of the transition layer for the model with 35 points\n",
      " flipped on each side of 0 is 0.45941\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in [15, 20, 25, 30, 35]:\n",
    "    Carryout_logi_regression(data_input,\n",
    "                             labels_input,\n",
    "                             n=item,\n",
    "                             lr=.001, max_iter=100000,\n",
    "                             )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-bicycle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "189.531px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 265.30080799999996,
   "position": {
    "height": "40px",
    "left": "849.704px",
    "right": "20px",
    "top": "120px",
    "width": "527.993px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
