{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CS547 HW1 Group 32**  \n",
    "Yue Cui  \n",
    "Gaoyu Liu\n",
    "\n",
    "Colab link:\n",
    "https://colab.research.google.com/github/052D/CS547_SP2021/blob/main/HW1/CS547_HW1_Group_32.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)\n",
    "$$\n",
    "\\nabla f(\\boldsymbol{x})= \\begin{pmatrix} 18x_1 \\\\\n",
    "                            2x_2 \n",
    "                            \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "(2)\n",
    "From fundemantal definition of calculus, we have\n",
    "\n",
    "$$\n",
    "\\boldsymbol{X_t}'=\\frac{d\\boldsymbol{X_t}}{dt}=\\lim_{\\Delta t\\to 0}\\frac{\\boldsymbol{X}_{t+\\Delta t}-\\boldsymbol{X}_{t}}{\\Delta t}=\\lim_{\\delta\\to 0}\\frac{\\boldsymbol{X}_{t+\\delta}-\\boldsymbol{X}_{t}}{\\delta}=\\lim_{\\delta\\to 0}\\frac{\\boldsymbol{x}_{\\lfloor \\frac{t}{\\delta} \\rfloor +1}-\\boldsymbol{x}_{\\lfloor \\frac{t}{\\delta} \\rfloor}}{\\delta}\n",
    "$$\n",
    "\n",
    "Now we have\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}_{\\lfloor \\frac{t}{\\delta} \\rfloor +1}-\\boldsymbol{x}_{\\lfloor \\frac{t}{\\delta} \\rfloor}=\\boldsymbol{x}_{n+1}-\\boldsymbol{x}_n=-\\delta\\nabla f(\\boldsymbol{x}_n)\n",
    "$$\n",
    "\n",
    "Therefore\n",
    "\n",
    "$$\n",
    "\\boldsymbol{X_t}'=\\lim_{\\delta\\to 0}\\frac{-\\delta\\nabla f(\\boldsymbol{x}_n)}{\\delta}=\\lim_{\\delta\\to 0}-\\nabla f(\\boldsymbol{x}_n)=-\\nabla f(\\boldsymbol{x}_n) \\\\\n",
    "=- \\begin{pmatrix} 18x_1 \\\\\n",
    "            2x_2\n",
    "            \\end{pmatrix}_{\\lfloor t/\\delta \\rfloor} \n",
    "=-\\begin{pmatrix} 18X_1 \\\\\n",
    "            2X_2\n",
    "            \\end{pmatrix}_{t}\n",
    "$$\n",
    "\n",
    "The system of ODE for $\\lim_{\\delta\\to 0}\\boldsymbol{X}_t$ is\n",
    "\n",
    "$$\n",
    "X_1'+18X_1=0 \\\\\n",
    "X_2'+2X_2=0\n",
    "$$\n",
    "\n",
    "(3)\n",
    "Sove the system of ODE\n",
    "\n",
    "$$\n",
    "X_1'+18X_1=0 \\\\\n",
    "\\frac{dX_1}{dt}\\frac{1}{X_1}=-18 \\\\\n",
    "\\frac{1}{X_1}dX_1=-18 dt \\\\\n",
    "\\ln{X_1}=-18t+C_1 \\\\\n",
    "X_1=Ae^{-18t}\n",
    "$$\n",
    "\n",
    "Similarly we have $X_2=Be^{-2t}$. Now substitute the initial condition of $\\boldsymbol{x}_0=\\boldsymbol{X}_0=(1,2)$, we have\n",
    "\n",
    "$$\n",
    "A=1\\\\\n",
    "B=2\n",
    "$$\n",
    "\n",
    "The solution for the ODE is\n",
    "\n",
    "$$\n",
    "X_1=e^{-18t} \\\\\n",
    "X_2=2e^{-2t}\n",
    "$$\n",
    "\n",
    "From the solution of ODE, we can conclude that X converges exponentially to the minimum point of (0,0) from initial point of (1,2) at step 0 when t tends to infinity. This is the minimum converges rate of gradient decent when we choose a step size tending to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) Explicitly describe the gradient descent iteration $x_{n+1} = x_n − \\delta f′(x_n)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First compute the gradient:  \n",
    "\n",
    "$$\n",
    "f′(x_n) = 2 \\lambda x_n\n",
    "$$  \n",
    "\n",
    "Then we have the explicit expression for the gradient descent iteration: \n",
    "\n",
    "$$\n",
    "x_{n+1} = x_n − \\delta f′(x_n) = x_n − 2 \\delta \\lambda x_n \\\\\n",
    "x_{n+1} = (1 - 2 \\delta \\lambda) x_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) Describe the stability of gradient descent iteration for different values of $\\delta$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of the sign of $x_n$, then the gradient descent is stable, $x_{n+1}$ always tend to approach the optimal point $x = 0$. Hence, $\\|1 - 2 \\lambda \\delta \\| < 1$ should be satisfied.\n",
    "\n",
    "$$\n",
    "\\|1 - 2 \\lambda \\delta \\| < 1 \\\\\n",
    "0 < \\delta < \\frac{1}{\\lambda}, \\lambda > 0.\n",
    "$$\n",
    "\n",
    "Therefore, the gradient descent will be stable when $ 0 < \\delta < \\frac{1}{\\lambda} $ and converges to 0. The gradient descent is unstable and diverges for all other values of $\\delta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:34:41.536508Z",
     "start_time": "2021-02-07T00:34:36.209778Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown as md\n",
    "import time\n",
    "import random\n",
    "import matplotlib\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "#from pandas.plotting import autocorrelation_plot\n",
    "import matplotlib.offsetbox as offsetbox\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "import imageio\n",
    "import PIL\n",
    "\n",
    "def saver(fname):\n",
    "    plt.savefig(fname+\".png\",bbox_inches=\"tight\")\n",
    "    \n",
    "def legend(pos=\"bottom\",ncol=3,extra=False):\n",
    "    if pos==\"bottom\":\n",
    "        extra = 0.15 if extra else 0\n",
    "        plt.legend(bbox_to_anchor=(0.5,-0.2-extra), loc='upper center',facecolor=\"lightgray\",ncol=ncol)\n",
    "    elif pos==\"side\":\n",
    "        plt.legend(bbox_to_anchor=(1.1,0.5), loc='center left',facecolor=\"lightgray\",ncol=1)\n",
    "        \n",
    "def textbox(txt,fname=None):\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.gca().add_artist(offsetbox.AnchoredText(\"\\n\".join(txt), loc=\"center\",prop=dict(size=30)))\n",
    "    plt.axis('off')\n",
    "    if fname is not None:\n",
    "        saver(fname)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:34:44.770938Z",
     "start_time": "2021-02-07T00:34:44.754679Z"
    }
   },
   "outputs": [],
   "source": [
    "# tries to get local version and then defaults to google drive version\n",
    "def getfile(location_pair, **kwargs):\n",
    "    (loc, gdrive) = location_pair\n",
    "    try:\n",
    "        out = pd.read_csv(loc, **kwargs)\n",
    "    except FileNotFoundError:\n",
    "        print(\"local file not found; accessing Google Drive\")\n",
    "        loc = 'https://drive.google.com/uc?export=download&id=' + \\\n",
    "            gdrive.split('/')[-2]\n",
    "        out = pd.read_csv(loc, **kwargs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:34:48.147641Z",
     "start_time": "2021-02-07T00:34:47.637002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local file not found; accessing Google Drive\n"
     ]
    }
   ],
   "source": [
    "columns=[\n",
    "\"CIC0\",\n",
    "\"SM1_Dz(Z)\",\n",
    "\"GATS1i\",\n",
    "\"NdsCH\",\n",
    "\"NdssC\",\n",
    "\"MLOGP\",\n",
    "\"LC50\" #response\n",
    "]\n",
    "fname = (\"qsar_fish_toxicity.csv\",\n",
    "         \"https://drive.google.com/file/d/1xd30VCQ2clQPzHDXpDi-VPU6pGTIUmQg/view?usp=sharing\")\n",
    "\n",
    "data_raw = getfile(fname, sep=\";\", names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:34:54.765891Z",
     "start_time": "2021-02-07T00:34:54.752275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIC0</th>\n",
       "      <th>SM1_Dz(Z)</th>\n",
       "      <th>GATS1i</th>\n",
       "      <th>NdsCH</th>\n",
       "      <th>NdssC</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>LC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.260</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1.676</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.453</td>\n",
       "      <td>3.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.189</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.348</td>\n",
       "      <td>3.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.125</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.348</td>\n",
       "      <td>3.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.027</td>\n",
       "      <td>0.331</td>\n",
       "      <td>1.472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.807</td>\n",
       "      <td>3.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.094</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.886</td>\n",
       "      <td>5.390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIC0  SM1_Dz(Z)  GATS1i  NdsCH  NdssC  MLOGP   LC50\n",
       "0  3.260      0.829   1.676      0      1  1.453  3.770\n",
       "1  2.189      0.580   0.863      0      0  1.348  3.115\n",
       "2  2.125      0.638   0.831      0      0  1.348  3.531\n",
       "3  3.027      0.331   1.472      1      0  1.807  3.510\n",
       "4  2.094      0.827   0.860      0      0  1.886  5.390"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:34:57.759537Z",
     "start_time": "2021-02-07T00:34:57.744388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIC0</th>\n",
       "      <th>SM1_Dz(Z)</th>\n",
       "      <th>GATS1i</th>\n",
       "      <th>MLOGP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.260</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1.676</td>\n",
       "      <td>1.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.189</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.863</td>\n",
       "      <td>1.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.125</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.027</td>\n",
       "      <td>0.331</td>\n",
       "      <td>1.472</td>\n",
       "      <td>1.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.094</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.860</td>\n",
       "      <td>1.886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIC0  SM1_Dz(Z)  GATS1i  MLOGP\n",
       "0  3.260      0.829   1.676  1.453\n",
       "1  2.189      0.580   0.863  1.348\n",
       "2  2.125      0.638   0.831  1.348\n",
       "3  3.027      0.331   1.472  1.807\n",
       "4  2.094      0.827   0.860  1.886"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    3.770\n",
       "1    3.115\n",
       "2    3.531\n",
       "3    3.510\n",
       "4    5.390\n",
       "Name: LC50, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature, response = [\"CIC0\", \"SM1_Dz(Z)\", \"GATS1i\", \"MLOGP\"], \"LC50\"\n",
    "data=data_raw.copy()\n",
    "X=data[feature]\n",
    "Y=data[response]\n",
    "display(X.head())\n",
    "display(Y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use sklearn to find the formula (i.e., coefficients) for the linear regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:35:09.924631Z",
     "start_time": "2021-02-07T00:35:08.506504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44750162,  1.22068139, -0.77463965,  0.38310065])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.1943526381758236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X, Y)\n",
    "coe_sklearn = reg.coef_\n",
    "display(coe_sklearn)\n",
    "intrcpt_slkearn = reg.intercept_\n",
    "display(intrcpt_slkearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T02:49:34.993633Z",
     "start_time": "2021-02-05T02:49:34.986793Z"
    }
   },
   "source": [
    "The expression of the linear regression is  \n",
    "**LC50 = 0.4475 $\\times$ CIC0 + 1.2207 $\\times$ SM1 Dz(Z) - 0.7746 $\\times$ GATS1i + 0.3831 $\\times$ MLOGP + 2.1944**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Numpy Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derive the explicit formula for multidimensional linear regression and implement it in numpy to get explicit coefficients.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the normal equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are more than one varibale as input $x$ in the linear regression, we have the design matrix $X_{n \\times (p+1)}$ , where $n$ is the number of the training samples and $p$ is the number of the variables considered in the linear regression model. Each training same is a row in the design matrix. The additional column in the design matrix is $1$'s to account for the intercept of the linear regression. Thus, we have parameter vector $P_{(p+1) \\times 1} = \\left ( m^T, b \\right)^T$. In summary, the linear regression model should look like  \n",
    "$$\n",
    "y_n = X_{n \\times (p+1)} \\   P_{(p+1) \\times 1}\n",
    "$$\n",
    "To obtain the optimal parameters $P^*$ of the linear regression model, one can compute the mean squared error (MSE) of the predicted $y_n$ and the ground truth $y_{train}$, which is\n",
    "$$\n",
    "\\Lambda(P) = \\frac{1}{n} \\sum_{i = 1}^{N} \\left ( y_{train,\\ i} -   X_{i} \\  P_{(p+1) \\times 1} \\  \\right )^2\n",
    "$$\n",
    "Take the derivative of the MSE $\\Lambda(P)$ with respect to the parameters $P$ and make it equal to $0$, the solution of which is the solution for the multivariate linear regression.\n",
    "$$\n",
    "\\nabla_{P} \\  \\Lambda(P) = 0 \\\\\n",
    "\\nabla_{P} \\ \\left(y_{train} -   X P \\  \\right)^T \\left(y_{train} -   X  P \\  \\right) = 0 \\\\\n",
    "2 X^T X P - 2 X^T y_{train} = 0 \\\\\n",
    "P = \\left(X^T X \\right)^{-1} X^T y_{train}\n",
    "$$\n",
    "The Pyhton implementation of the normal equation is shown in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:35:16.552980Z",
     "start_time": "2021-02-07T00:35:16.540015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Method 1 ------\n",
      "The coefficients of the linear regression model are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.44750162,  1.22068139, -0.77463965,  0.38310065])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept of the linear regression model is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1943526381757947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "XX = np.hstack([np.array(X), np.array(\n",
    "    [1]*X.shape[0]).reshape((X.shape[0], 1))])\n",
    "m = np.linalg.inv(XX.T@XX)@(XX.T)@(Y)\n",
    "print(f'----- Method 1 ------')\n",
    "print(f'The coefficients of the linear regression model are:')\n",
    "display(m[:-1])\n",
    "print(f'The intercept of the linear regression model is:')\n",
    "display(m[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are same as (1):  \n",
    "**LC50 = 0.4475 $\\times$ CIC0 + 1.2207 $\\times$ SM1 Dz(Z) - 0.7746 $\\times$ GATS1i + 0.3831 $\\times$ MLOGP + 2.1944**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T22:13:29.722551Z",
     "start_time": "2021-01-31T22:13:29.699613Z"
    }
   },
   "source": [
    "The gradient decent is implemented in the cell below.  \n",
    "\n",
    "More specifically, a class named **LinearRegression_multi** is defined to get multivariate linear regression models. The method **gradient_descent** in the class conducts the gradient decent inparticular.\n",
    "\n",
    "For each iteration of the gradient descent, all training data are used (1 epoch). The cost, i.e. the difference between the predicted $y$ and the ground truth $y_{train}$, \n",
    "$$\n",
    "\\epsilon_i(P) \\  = \\  y_{train,\\ i} \\  - \\   X_{i}  P\n",
    "$$\n",
    "as well as the gradient of the cost fucntion $\\Lambda(P)$ with respect to the learning rate $\\delta$ at $\\delta = 0$ \n",
    "$$\n",
    "\\nabla\\Lambda (P) \\  = \\  -\\frac{2}{n} \\sum_{i = 1}^{n} \\epsilon_i(P) X_{i}\n",
    "$$\n",
    "is computed in the function **Cost**. \n",
    "\n",
    "The parameters $P$ is then updated by $\\delta$ and the computed gradient $\\nabla\\Lambda (P)$:\n",
    "$$\n",
    "P_{i + 1} = P_i - \\delta \\nabla\\Lambda (P)\n",
    "$$\n",
    "where $i$ is the iteration step number. \n",
    "\n",
    "The number of the iterations for the gradient descent is controlled by two factors: (1) maximum allowable number of iterations; (2) the gradient step L2 norm $\\| \\nabla\\Lambda (P) \\|^2$. Both factors are compared with the input tolerance during each iteration.  \n",
    "\n",
    "The detailed Python implementation is presented below, as well as the computed optimal parameters $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:35:24.213283Z",
     "start_time": "2021-02-07T00:35:24.188133Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class LinearRegression_multi:\n",
    "    def __init__(self, x, y):\n",
    "        self.xvals = np.array(x)\n",
    "        self.nsamples = self.xvals.shape[0]\n",
    "        self.nvars = self.xvals.shape[1]\n",
    "\n",
    "        self.yvals = np.array(y).reshape((self.nsamples, 1))\n",
    "\n",
    "        self.XXvals = np.hstack(\n",
    "            [self.xvals, np.array(([1]*self.nsamples)).reshape((self.nsamples, 1))])\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.ctr = 0\n",
    "        self.callbacktext = []\n",
    "        self.p = [np.zeros([self.nvars, 1]), 0.]\n",
    "        self.lr = 0.0001\n",
    "        #self.b = 0.\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_function(p):\n",
    "        (m, b) = p\n",
    "\n",
    "        def l_f(x):\n",
    "            return x@m + b\n",
    "        return l_f\n",
    "\n",
    "    def Cost(self, p, include_gradient=False):\n",
    "        err = self.yvals-self.linear_function(p)(self.xvals)\n",
    "        cost = np.mean(err**2)\n",
    "        # print(err)\n",
    "        if include_gradient:\n",
    "            out = -2*np.mean(err*self.XXvals, axis=0)\n",
    "            return (cost, out)\n",
    "        else:\n",
    "            return cost\n",
    "\n",
    "    def gradient_descent(self, epochs, p=None, lr=None,\n",
    "                         precision=0.01):\n",
    "        if lr == None:\n",
    "            lr = self.lr\n",
    "        if p == None:\n",
    "            p = self.p\n",
    "        m = p[0]\n",
    "        b = p[1]\n",
    "        step_size = 1.\n",
    "        i = 0\n",
    "        cost_history = np.array([])\n",
    "        m_history = np.array([m])\n",
    "        b_history = np.array([b])\n",
    "        while step_size > precision and i < epochs:\n",
    "            cost, gradient = self.Cost([m, b], True)\n",
    "            cost_history = np.append(cost_history, cost)\n",
    "            m = m - lr*gradient[:-1].reshape((self.nvars, 1))\n",
    "            b = b - lr*gradient[-1]\n",
    "            m_history = np.append(m_history, m.T)\n",
    "            b_history = np.append(b_history, b)\n",
    "            step_size = np.linalg.norm(gradient)\n",
    "            i += 1\n",
    "        #\n",
    "        print(f'Gradient descent total iterations: {i}')\n",
    "        return m.T, b, cost_history, m_history, b_history\n",
    "\n",
    "    def metric(self, p):\n",
    "        (m, b) = p\n",
    "        err = self.yvals-self.linear_function(p)(self.xvals)\n",
    "        return np.mean(np.abs(err))\n",
    "\n",
    "    def callback(self, x, verbose=False):\n",
    "        (m, b) = p\n",
    "        outstr = \"ctr={0:}; (m,b)=({1:.3f},{2:.2E}); error={3:.2E}\".format(\n",
    "            self.ctr, m, b, self.Cost(p))\n",
    "        self.callbacktext.append(outstr)\n",
    "        if verbose:\n",
    "            print(outstr)\n",
    "        self.ctr += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T02:58:13.859889Z",
     "start_time": "2021-02-05T02:58:13.842932Z"
    }
   },
   "source": [
    "Now carry out the gradient descent for the linear regration given the $X$ and $y$ data. The maximum iteration number is set to be 10000. The tolerance for the L2 norm of the gradient update step size is $10^{-10}$. By trying several different learning rate or $\\delta$, it was found that $\\delta = 0.05$ could be a good choice with stable condition and reseaonable number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:35:28.721134Z",
     "start_time": "2021-02-07T00:35:27.386615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent total iterations: 7521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.44750162,  1.22068139, -0.77463965,  0.38310065]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.1943526365103576"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAElCAYAAAALP/6mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfgklEQVR4nO3deZhcZZ328e+dhR3CkqgYlhCWMMRhE9nlBWUUhFYHkV0dRRkFdRQUWXznQtSRkVeUGUBlUEHZRkGURhBxNKDsAWUJphFaeIksCWBC2JP0b/54nq5Umq7K6XSfOtWp+3Nd5zp19vt0J/Xrsz1HEYGZmRnAmKoDmJlZ+3BRMDOzGhcFMzOrcVEwM7MaFwUzM6txUTAzsxoXBWtrkj4h6SlJz0vaoOo8RUl6RNK++fMpki6oOpNZES4KVoikIyTNzF/OT0i6TtKew1xn7YuzwfTxwFnAOyJirYh4Zjjbq1vvYZJul/SCpLn587GSNBLrHygi/i0iPjrc9UiaIikkjWsyz2mSFklamLsHJZ0jacPhbr8seZ+2qDqHJS4KtlySjge+Bfwb8HpgE+A84D0lb/r1wGrArKEuqOQ1/74lnQCcDZwJvCFv4+PAHsAqDdY1dqjbr9h/R8TawPrAP5L28652LgzWRiLCnbuGHTABeB54f5N5ViUVjcdz9y1g1TxtInANMB94Fvgd6Y+RHwF9wEt5/ScOWOdWwAtA5Om/yeN3B+4EFuT+7nXLzAC+Ctyc17vFIPvyAvC+5ezzhcC3gWvz/PsCBwB/AJ4DHgNOG7DMB4BHgWeAU4FHgH3ztNOAi+vm3RW4Jf9M7gH2HrAPX877sBD4FTAxT/v/dT+P54HdBsm+zLbyuLF5O/+vbtyBwB9zhluAbeumfQH4a95+D/D2uvWcAjycp90FbJynbQ3ckH/HPcAhA36e5wK/yMvdDmyep92U9+mFvE+HVv1vvtO7ygO4a+8O2A9YDIxrMs/pwG3A64BJ+Uvmy3na14DvAONz91ZAeVrti7PBeqfkL4xxeXh94G/5C3gccHge3iBPn5G/OKfn6eOHui95vgtJRWcPUgFbDdgb+Ps8vC3wFPDePP82+QttL1KBPCtv5zVFAZhMKhzvyuv6hzw8qW4fHiYVxdXz8BmD/TwaZK9ta5Df0e35847AXGAX0hf9h/LvYlVgGqnovbFum/1f4J8H7svzCNgO2ABYMy/z4fxz3xF4Gphe9/N8Ftg5T78EuLwuWzCggLurrvPpI1ueDYCnI2Jxk3mOBE6PiLkRMQ/4EumLG2ARsCGwaUQsiojfRf4mWAEHAH+OiB9FxOKIuAyYDXTVzXNhRMzK0xcNWH7iwH2RdIuk+ZJekrRX3bw/j4ibI6IvIl6OiBkRcV8evhe4DPg/ed6DgWsi4qaIeAX4v6SjoMEcBVwbEdfmdd0AzCQViX4/iIgHI+Il4MfA9kP4GTXyOKmoAnwM+G5E3B4RSyLiIuAV0hHMElJx2EbS+Ih4JCIezst9FPhiRPREck+k6zwHAo9ExA/yz/1u4Mr8c+n304i4I//sLxmhfbISuCjY8jwDTGx2cRN4I+nUSb9H8zhI5+4fAn4lqVfSScPIMnA7/duaXDf8WJPlX7MvEbF7RKybp9X/f1hmPZJ2kfRbSfMkLSBdh5hYl6s2f0S8kNc3mE2B9+dCNF/SfGBPUuHs92Td5xeBtZrsU1GTSX+t92c4YUCGjUlHBw8BnyEdccyVdLmk/t/lxqSjmMH2aZcB6zuSdC2jzH2yErgo2PLcCrwMvLfJPI+Tvhj6bZLHERELI+KEiJhK+ov+eElvz/MN9Yhh4Hb6t/XXuuFm67yV9BdxkQvkA9dzKXA16Rz6BNIpsf67lZ4gfWECIGkN0hHWYB4DfhQR69Z1a0bEGSuQqZB8wb2LdD2nP8NXB2RYIx95ERGXRsSepJ91AP9et9zmDfbpxgHrWysiPrEiea1aLgrWVEQsAP4VOFfSeyWtIWm8pP0lfT3PdhnwRUmTJE3M818MIOlASVvk2z2fI52eWJKXewqYOoQ41wJb5dtjx0k6lHQ+/5qC+zKfdGrrPEkHS1pL0hhJ25POizezNvBsRLwsaWfgiLppVwAHStpT0iqk8/eN/m9dDHRJeqeksZJWk7S3pI0K7MI80mmpQj+z/Hv6O9Lv5w2kax0A/wV8PB/9SNKakg6QtLakaZLeJmlV0h8DL7H093UB8GVJW+blts3PjlxD+r18IG9zvKS35G0XMdR/B1YiFwVbrog4Czge+CLpi+kx4JPAz/IsXyGdF7+XdCHy7jwOYEvg16QLsbcC50XEjDzta6RiMl/S5wrk6D9/fQLp9MyJwIER8fQQ9uXreV9OJF1sfQr4LumOm1uaLHoscLqkhaSi9+O6dc4CjiMdTTxBuvg9p8H2HyMdqZzC0p/l5ynwfzEiXiTfXZV/Zrs2mPVQSc+T7iy6mvSzenNE9B+9zSRdVzgnZ30I+Ke87KrAGaQLxU+Sbh44JU87K+/3r0gF/nvA6hGxEHgHcBjpaO5J0tHFqsvbp+w04KK8T4cUXMZK0n8XiJmZmY8UzMxsKRcFMzOrcVEwM7MaFwUzM6txUTAzsxoXBet4ko6S9ICkBZKeKXJ7bIF1ri/pqtw896OSjljReSXNkPSyUrPlz0vqGW4+s0aaNV1gttKTNAH4Puk+/vskrcmyzWasqHOBV0lNc28P/ELSPfmZhhWZ95MR4Rf1WOn8nIJ1NKUX+dxJehhrBqmF0QeHuc41SQ+Fval/XZJ+BPw1Ik4a6ryS+nO5KFjpfPrIOl0XcGlE7EVqRmOGpL+vn0HSNfWNvQ3oBmtiYytgyYDicg+pSe8Vnfdrkp6WdLOkvYe2i2bF+fSRdSxJm5LaKdoOICJuk3Qj8D5Scx3k8QcOcdVrkd7HUG8Bqf2kFZn3C8ADpFNMhwHdkrava9LabMT4SME62VHArRGxpG7cOqS3gA3H83k99dYhvXVsyPPm9x4sjIhX8rsPbmbZ9y+YjRgXBetkm5AajQPSXUCkF+f8sn4mSdfV3fkzsLtukPU+CIyTtGXduO0Y/F3TQ5m3X7C02W6zEeULzdaxJJ1AepvYXqQv2YuAZyLiqBFY9+WkL++Pku4oupb0PunXfNk3m1fSuqTXZt5IesXnocD5wI4R4VtTbcT5SME62XdIzXz3AHfkzx8doXUfS3rH8lzS+ww+0V8Q8pHHKUXmJb3X+iukZrafBj5Feje0C4KVwkcKZmZW4yMFMzOrcVEwM7MaFwUzM6txUTAzs5pR/UTzxIkTY8qUKVXHMDMbVe66666nI2LSYNNGdVGYMmUKM2fOrDqGmdmoIunRRtN8+sjMzGpcFMzMrMZFwczMalwUzMysZlQWBUldks5fsGBgM/RmZjYco7IoRER3RBwzYcKEqqOYma1URmVRGI7eXpg+HcaNS/3e3qoTmZm1j44rCl1dMHs2LFmS+l1dVScyM2sfHVcUenqgry997utLw2ZmlnRcUZg2DcbkvR4zJg2bmVnScUWhuxu23hrGjk397u6qE5mZtY9R3fbRipg6FWY1eyW6mVkH67gjBTMza8xFwczMalwUzMysxkXBzMxqXBTMzKzGRcHMzGpcFMzMrMZFwczMalwUzMysxkXBzMxqXBTMzKzGRcHMzGpcFMzMrMZFwczMalwUzMysxkXBzMxqXBTMzKzGRcHMzGpcFMzMrMZFwczMalwUzMysxkXBzMxqXBTMzKzGRcHMzGpcFMzMrMZFwczMalwUzMysxkXBzMxqXBTMzKzGRcHMzGpcFMzMrMZFwczMalwUzMysxkXBzMxqOq4o9PbC9Okwblzq9/ZWncjMrH20TVGQNFXS9yRdUeZ2urpg9mxYsiT1u7rK3JqZ2ehSalGQ9H1JcyXdP2D8fpJ6JD0k6SSAiOiNiKPLzAPQ0wN9felzX18aNjOzpOwjhQuB/epHSBoLnAvsD2wDHC5pm5Jz1EybBmPyXo8Zk4bNzCxpWhQkrSbpYElnS/qJpB9KOlHS9CIrj4ibgGcHjN4ZeCgfGbwKXA68p2hgScdImilp5rx584ouVtPdDVtvDWPHpn5395BXYWa20mpYFCSdBtwM7AbcDnwX+DGwGDhD0g2Stl2BbU4GHqsbngNMlrSBpO8AO0g6udHCEXF+ROwUETtNmjRpyBufOhVmzYLFi1N/6tQhr8LMbKU1rsm0OyPitAbTzpL0OmCTFdimBhkXEfEM8PEVWJ+ZmY2QhkUhIn5RPyxpzYh4oW76XGDuCmxzDrBx3fBGwOMrsB4zMxthy73QLGl3SQ8Af8rD20k6bxjbvBPYUtJmklYBDgOuHsb6zMxshBS5++ibwDuBZwAi4h5gryIrl3QZcCswTdIcSUdHxGLgk8D1pELz44iYtSLhzcxsZDW7plATEY9Jy1wKWFJwucMbjL8WuLbIOszMrHWKHCk8Jml3ICStIulz5FNJVZHUJen8BQsWVBnDzGylU6QofBw4jnQr6Rxg+zxcmYjojohjJkyYUGUMM7OVznJPH0XE08CRLchiZmYVa1gUJP0nEI2mR8SnS0lkZmaVaXakMLNlKczMrC00e3jtolYGMTOz6i33moKkScAXSC2artY/PiLeVmIuMzOrQJG7jy4h3YK6GfAl4BHSU8lmZraSKVIUNoiI7wGLIuLGiPgIsGvJuZrycwpmZuUoUhQW5f4Tkg6QtAOpEbvK+DkFM7NyFGnm4iuSJgAnAP8JrAN8ttRUZmZWiSIPr12TPy4A9ik3jpmZValI09kXSVq3bng9Sd8vNZWZmVWiyDWFbSNifv9ARPwN2KG0RGZmVpkiRWGMpPX6ByStT8Emt83MbHQp8uX+DeAWSVfk4fcDXy0vkpmZVaXIheYfSpoJvA0QcFBEPFB6MjMza7kiF5o3Bx6OiHOA+4B96y88V8EPr5mZlaPINYUrgSWStgAuIDV3cWmpqZbDD6+ZmZWjSFHoi4jFwEHA2RHxWWDDcmOZmVkVCjVzIelw4INA/4Ns48uLZGZmVSlSFD4M7AZ8NSL+Imkz4OJyY5mZWRWK3H30APDpuuG/AGeUGcrMzKpR5EjBzMw6RMcVhd5emD4dxo1L/d7eqhOZmbWPjisKXV0wezYsWZL6XV1VJzIzax9FHl67YZBWUq8vNVWJenqgry997utLw2ZmlhQ5Upg4SCuprystUQHDeaJ52jQYk/d6zJg0bGZmSaGH1yRt0j8gaVMgyou0fMN5orm7G7beGsaOTf3u7hICmpmNUkVaST0V+L2kG/PwXsAx5UUq19SpMGtW1SnMzNpTkecUfilpR2BXUiupn42Ip0tPZmZmLdfw9JGkrXN/R2AT4HHgr8AmeZyZma1kmh0pHE86TfSNQaYF6f0KZma2EmlYFCLimNzfp3VxzMysSsu9piBpLHAAMKV+/og4q7xYZmZWhSJ3H3UDL5PeutZXbhwzM6tSkaKwUURsW3oSMzOrXJGH166T9I7Sk5iZWeWKHCncBlwlaQywiPSsQkTEOqUmMzOzlitypPAN0pvX1oiIdSJi7aoLwnDaPjIzs8aKFIU/A/dHRKXtHdUbTttHZmbWWJHTR08AMyRdB7zSP9K3pJqZrXyKFIW/5G6V3JmZ2UqqSIN4X2pFEDMzq16RJ5q3Aj7Ha59odttHZmYrmSKnj34CfAe4AFhSbhwzM6tSkaKwOCK+XXoSMzOrXMOiIGn9/LFb0rHAVSx799GzJWczM7MWa3akcBfpvQnKw5+vmxbA1LJCmZlZNZq9T2EzAEmrRcTL9dMkrVZ2MDMza70iTzTfUnCcmZmNcs2uKbwBmAysLmkHlp5GWgdYowXZzMysxZpdU3gn8E/ARkB9kxYLgVNKzGRmZhVpdk3hIuAiSe+LiCtbmMnMzCrS7PTRURFxMTBF0vEDp1fZIJ6kLqBriy22qCqCmdlKqdmF5jVzfy1g7UG6ygyn6ezeXpg+HcaNS/3e3hICmpmNUs1OH31X0ljguYj4ZgszlaqrC2bPhr6+1O/qglmzqk5lZtYemt6SGhFLgHe3KEtL9PSkggCp39NTbR4zs3ZS6DkFSedIequkHfu70pOVZNo0GJP3esyYNGxmZkmRBvF2z/3T68YFMCqbzu7uTqeMenpSQejurjqRmVn7KPKSnX1aEaRVpk71NQQzs0aKHCkg6QBgOlBr8ygiTm+8hJmZjUbLvaYg6TvAocCnSE1dvB/YtORcZmZWgSIXmnePiA8Cf8vva94N2LjcWGZmVoUiReGl3H9R0huBRcBm5UUyM7OqFLmmcI2kdYEzgbtJdx5dUGYoMzOrRpG7j76cP14p6RpgtYhYUG4sMzOrwnKLgqSDBhm3ALgvIuaWksrMzCpR5PTR0aSLy7/Nw3sDtwFbSTo9In5UUjYzM2uxIkWhD/i7iHgKQNLrgW8DuwA3AS4KZmYriSJ3H03pLwjZXGCriHiWdCeSmZmtJIocKfwuX2D+SR4+GLhJ0prA/LKCmZlZ6xUpCscBBwF7kp5ovgi4MiICWKnaRTIz63RFbkkNSb8HXiU9o3BHLgiV8es4zczKUaTto0OAO0injQ4Bbpd0cNnBmhnO6zjNzKyxIqePTgXe0v9MgqRJwK+BK8oMZmZmrVfk7qMxAx5Se6bgcmZmNsoUOVL4paTrgcvy8KHAteVFMjOzqhS50Px5Se8D9iDdfXR+RFxVejIzM2u5Qm9ei4grgStLzmJmZhVreG1A0kJJzw3SLZT0XCtDjqTeXpg+HcaNS/3e3qoTmZm1j4ZHChGxdiuDtEpXF8yeDX19qd/VBbNmVZ3KzKw9NDtSWGt5CxeZp9309KSCAKnf01NtHjOzdtLs1tKfS/qGpL1yO0cASJoq6eh8R9J+5UccWdOmwZi812PGpGEzM0saFoWIeDvwP8A/A7MkLZD0DHAx8AbgQxEx6h5g6+6GrbeGsWNTv7u76kRmZu2j6d1HEXEtK9kzCVOn+hqCmVkjfjLZzMxqXBTMzKzGRcHMzGqKNJ39mncwDzbOzMxGvyJHCtPrBySNBd5cThwzM6tSs4fXTpa0ENi2vokLYC7w85YlNDOzlmn2nMLXclMXZ0bEOrlbOyI2iIiTW5jRzMxapMjpo2v6n2iWdJSksyRtWnIuMzOrQJGi8G3gRUnbAScCjwI/LDWVmZlVokhRWBwRAbwHODsizgZWyhZUzcw6XZGX7CyUdDLwAeCt+e6j8eXGMjOzKhQ5UjgUeAX4SEQ8CUwGziw1VYn8kh0zs8aWWxRyIbgEmCDpQODliBi11xT6X7KzZMnSl+yYmVlS5InmQ4A7gPcDhwC3Szq47GBl8Ut2zMwaK3JN4VTgLRExF0DSJODXQGXvUpDUBXRtscUWQ1522rSlr+P0S3bMzJZV5JrCmP6CkD1TcLnSRER3RBwzYcKEIS/rl+yYmTVW5Ejhl/nVm5fl4UOB68qLVC6/ZMfMrLHlFoWI+Lykg4A9AQHnR8RVpSczM7OWa1gUJG0BvD4ibo6InwI/zeP3krR5RDzcqpBmZtYaza4NfAtYOMj4F/M0MzNbyTQrClMi4t6BIyNiJjCltERmZlaZZkVhtSbTVh/pIGZmVr1mReFOSR8bOFLS0cBd5UUql5u5MDNrrNndR58BrpJ0JEuLwE7AKsA/lpyrNP3NXPT1LW3mwreompklDYtCRDwF7C5pH+BNefQvIuI3LUlWEjdzYWbWWJHnFH4L/LYFWVrCzVyYmTVWaXMVVXAzF2ZmjRVp5mKl4mYuzMwa67gjBTMza6wji4JvSzUzG1xHFgW/fc3MbHAdWRR8W6qZ2eA6sihMm5ZuRwXflmpmVq8ji4JvSzUzG1xHFgUzMxtcRxYFX2g2MxtcRxaF/mYuYGnDeGZm1qFFYdy45sNmZp2qI4vC4sXNh83MOlVHFoWxY5sPm5l1qo4sCosWNR82M+tUHVkUzMxscC4KZmZW46JgZmY1LgpmZlbjomBmZjUuCmZmVuOiYGZmNS4K2aWXVp3AzKx6LgrZkUdWncDMrHouCmZmVtORRWHy5KoTmJm1p44sCjfdNPj4GTNaGsPMrO10ZFGYOnXw8fvs09ocZmbtpiOLgpmZDc5FYYD11qs6gZlZdTq2KBx77ODj5893YTCzztU2RUHSmpIukvRfkkp/auDccxtPmz8fJDjuuLJTmJm1l1KLgqTvS5or6f4B4/eT1CPpIUkn5dEHAVdExMeAd5eZq9+WWzafft55qTjssUcr0piZVa/sI4ULgf3qR0gaC5wL7A9sAxwuaRtgI+CxPNuSknMB8OCDxea75ZZUHPq73t5yc5mZVaXUohARNwHPDhi9M/BQRPRGxKvA5cB7gDmkwtA0l6RjJM2UNHPevHnDzrgizVtsvvmyRWJgt8Yaw45lZlaJcRVsczJLjwggFYNdgP8AzpF0ANDdaOGIOB84H2CnnXaK4Ya5+GKYMCGdKhopL72UioOZWdkuuQSOOGLk1lfFhebBvi4jIl6IiA9HxCci4pJWBjr3XIiAtddu5VbNzIZvpBvzrKIozAE2rhveCHi8ghyv8dxzqTi4bSQz61RVFIU7gS0lbSZpFeAw4OoKcjQ0Z04qDv3d+PFVJzIza42yb0m9DLgVmCZpjqSjI2Ix8EngeuBPwI8jYlaZOYbr1VeXLRIDu29+s+qEZtapLhnhk+2KGPa12srstNNOMXPmzKpjmJmNKpLuioidBpvWNk80D4WkLknnL1iwoOooZmYrlVFZFCKiOyKOmTBhQtVRzMxWKqOyKJiZWTlcFMzMrMZFwczMalwUzMysZlTfkippHvDoCi4+EXh6BOOUod0ztns+aP+M7Z4P2j9ju+eD9su4aURMGmzCqC4KwyFpZqP7dNtFu2ds93zQ/hnbPR+0f8Z2zwejI2M/nz4yM7MaFwUzM6vp5KJwftUBCmj3jO2eD9o/Y7vng/bP2O75YHRkBDr4moKZmb1WJx8pmJnZAC4KZmZW05FFQdJ+knokPSTppBZu9/uS5kq6v27c+pJukPTn3F+vbtrJOWOPpHfWjX+zpPvytP+QRuaN0JI2lvRbSX+SNEvSv7RhxtUk3SHpnpzxS+2WMa97rKQ/SLqmTfM9ktf9R0kz2y2jpHUlXSFpdv73uFub5ZuWf3b93XOSPtNOGVdYRHRUB4wFHgamAqsA9wDbtGjbewE7AvfXjfs6cFL+fBLw7/nzNjnbqsBmOfPYPO0OYDfS+66vA/YfoXwbAjvmz2sDD+Yc7ZRRwFr583jgdmDXdsqY1308cClwTbv9nvO6HwEmDhjXNhmBi4CP5s+rAOu2U74BWccCTwKbtmvGIe1PlRuvZIfTD//6uuGTgZNbuP0pLFsUeoAN8+cNgZ7BcpHeVLdbnmd23fjDge+WlPXnwD+0a0ZgDeBuYJd2ykh67/j/AG9jaVFom3x5fY/w2qLQFhmBdYC/kG+Eabd8g+R9B3BzO2ccSteJp48mA4/VDc/J46ry+oh4AiD3X5fHN8o5OX8eOH5ESZoC7ED6S7ytMuZTM38E5gI3RES7ZfwWcCLQVzeunfIBBPArSXdJOqbNMk4F5gE/yKfgLpC0ZhvlG+gw4LL8uV0zFtaJRWGw83XteF9uo5yl55e0FnAl8JmIeK7ZrA2ylJoxIpZExPakv8h3lvSmJrO3NKOkA4G5EXFX0UUa5Cj797xHROwI7A8cJ2mvJvO2OuM40mnWb0fEDsALpFMxjVT5f2UV4N3AT5Y3a4Msbfd91IlFYQ6wcd3wRsDjFWUBeErShgC5PzePb5RzTv48cPyIkDSeVBAuiYiftmPGfhExH5gB7NdGGfcA3i3pEeBy4G2SLm6jfABExOO5Pxe4Cti5jTLOAebkI0CAK0hFol3y1dsfuDsinsrD7ZhxSDqxKNwJbClps1zlDwOurjDP1cCH8ucPkc7j948/TNKqkjYDtgTuyIekCyXtmu9S+GDdMsOS1/c94E8RcVabZpwkad38eXVgX2B2u2SMiJMjYqOImEL6t/WbiDiqXfIBSFpT0tr9n0nnxO9vl4wR8STwmKRpedTbgQfaJd8Ah7P01FF/lnbLODRVXtCoqgPeRbqz5mHg1BZu9zLgCWAR6S+Eo4ENSBcl/5z769fNf2rO2EPdHQnATqT/xA8D5zDggtww8u1JOnS9F/hj7t7VZhm3Bf6QM94P/Gse3zYZ69a/N0svNLdNPtI5+3tyN6v//0CbZdwemJl/zz8D1munfHndawDPABPqxrVVxhXp3MyFmZnVdOLpIzMza8BFwczMalwUzMysxkXBzMxqXBTMzKzGRcEMkHRL7k+RdMQIr/uUwbZl1o58S6pZHUl7A5+LiAOHsMzYiFjSZPrzEbHWCMQzK52PFMxIX9z54xnAW3Mb+Z/Nje+dKelOSfdK+uc8/95K7564FLgvj/tZbmBuVn8jc5LOAFbP67ukfltKzpR0f25P/9C6dc/Q0vcJXFJ5G/vWMcZVHcCszZxE3ZFC/nJfEBFvkbQqcLOkX+V5dwbeFBF/ycMfiYhnc/Mbd0q6MiJOkvTJSA34DXQQ6cnd7YCJeZmb8rQdgOmkdnBuJrWp9PuR3lmzgXykYNbcO4AP5qa6byc1Y7BlnnZHXUEA+LSke4DbSI2fbUlzewKXRWr19SngRuAtdeueExF9pOZGpozAvpgtl48UzJoT8KmIuH6ZkenawwsDhvcFdouIFyXNAFYrsO5GXqn7vAT/X7UW8ZGC2bIWkl5F2u964BO5SXEkbZVbFh1oAvC3XBC2Jr0itN+i/uUHuAk4NF+3mER6XesdI7IXZivIf32YLeteYHE+DXQhcDbp1M3d+WLvPOC9gyz3S+Djku4ltYJ5W92084F7Jd0dEUfWjb+K9ErGe0it054YEU/momJWCd+SamZmNT59ZGZmNS4KZmZW46JgZmY1LgpmZlbjomBmZjUuCmZmVuOiYGZmNf8LiE2uK23Y21kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR = LinearRegression_multi(X, Y)\n",
    "\n",
    "delta = 0.05\n",
    "m_gd, b_gd, cost_his, m_his, b_his = LR.gradient_descent(10000, lr=delta,\n",
    "                                                         precision=1e-10)\n",
    "display(m_gd)\n",
    "display(b_gd)\n",
    "\n",
    "title = []\n",
    "title.append(\"Cost for Gradient Descent\")\n",
    "title.append(r\"$\\delta={:.2f}$\".format(delta))\n",
    "plt.figure()\n",
    "plt.semilogy(cost_his, 'bo', ms=4)\n",
    "plt.ylabel(\"Cost (logarithmic scale)\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.title(\"\\n\".join(title))\n",
    "saver(\"increasing_cost\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T02:35:14.067839Z",
     "start_time": "2021-02-02T02:35:14.057869Z"
    }
   },
   "source": [
    "The results agree with (1) and (2):  \n",
    "**LC50 = 0.4475 $\\times$ CIC0 + 1.2207 $\\times$ SM1 Dz(Z) - 0.7746 $\\times$ GATS1i + 0.3831 $\\times$ MLOGP + 2.1944**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246.983px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 248.304808,
   "position": {
    "height": "40px",
    "left": "1207.69px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
